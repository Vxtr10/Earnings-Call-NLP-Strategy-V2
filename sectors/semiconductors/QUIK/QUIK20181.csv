2018
1
2018-02-15 17:00:00
"Operator: Good day, ladies and gentlemen, and welcome to the First Quarter 2018 Earnings Conference Call. At this time, all participants are in a listen-only mode. Later we'll conduct a question-and-answer session and instructions will follow at that time. [Operator Instructions] As a reminder, this conference is being recorded. I would now like to introduce your host for today's conference Ms. Moriah Shilton with Investor Relations. Ms. Shilton, you may begin.
Moriah Shilton: Thank you, Sherrie. Welcome everyone, and thank you for joining us today for QuickLogic's First Quarter Fiscal 2018 Results Conference Call. With us today are Brian Faith, President and Chief Executive Officer, and Dr. Sue Cheung, Chief Financial Officer. Before we begin, I will read a short Safe Harbor statement. Some of the comments QuickLogic makes today are forward-looking statements that involve risks and uncertainties, including but not limited to, stated expectations relating to revenue from new and mature products, statements pertaining to QuickLogic's future stock performance, design activity and its ability to convert new design opportunities into production shipments; timing and market acceptance of its customers' products; schedule changes in projected projections start dates that could impact the timing of shipments; the Company's future evaluation systems; broadening the company's ecosystem partners, expected results and financial expectations for revenue, gross margin, operating expenses, profitability and cash. These statements should be considered in conjunction with the cautionary warnings that appear in QuickLogic's SEC filings. For additional information, please refer to the Company's SEC filings posted on its website and the SEC’s website. Investors are cautioned that all forward-looking statements in this call involve risks and uncertainties, and that future events may differ materially from the statements made. For more details of the risks, uncertainties and assumption, please refer to those discussed under heading Risk Factors in the Annual Report on Form 10-K for the fiscal year ended December 31, 2017, the Company filed with the SEC on March 9, 2018. These forward-looking statements are made as of today, the day of the conference call, and management undertakes no obligation to revise or publicly release any revisions of the forward-looking statements in light of any new information or future events. Please note, QuickLogic uses its website, the Company blog QuickLogic HotSpot, it's corporate Twitter account, Facebook page and LinkedIn page, as channels of distribution of information about its products, its planned financial and other announcements, its attendance at upcoming investor and industry conferences, and other matters. Such information may be deemed material information, and QuickLogic may use these channels to comply with its disclosure obligations under Regulation FD. This conference call is open to all and is being webcast live. We will start today's call with the Company's strategic update from QuickLogic’s CEO, Brian Faith. Then CFO, Sue Cheung will provide financial results and guidance. The company’s CTO and SVP of Engineering, Dr. Tim Saxe, will join the Q&A portion of the call. Brian will deliver closing remarks and open the call to questions. At this time, it is my pleasure to turn the call over to Brian Faith, President and CEO. Please go ahead, Brian.
Brian Faith: Thank you, Moriah. And thank you all for joining our Q1 2018 conference call. Last Friday we unveiled our new QuickAI solution that extends the reach of our core IP to enable the next generation of artificial intelligence in endpoint applications. The trademarked QuickAI solution that we presented with our three ecosystem partners leverages our EOS S3 SoC, our ArcticPro embedded FPGA IP and is market-ready. I have several other exciting updates to share today that bolster my confidence in our ability to grow revenue by more than 50% this year. Among those is the release of a new smartwatch earlier this week by a major OEM that incorporates our EOS S3 SoC. However, before I present the significant progress we have realized during the last quarter, I want to take a minute to go over two items that will limit our revenue growth in Q2. First, Amazon has not released its “Close Talk” specification. Close Talk is the unofficial name for the specification that will cover all of the design wins we have that must be able to advertise compliance with Alexa Voice Services in conjunction with the product release. We have been engaged with Amazon since mid-2017 and I believe the specification will be done in time for our customers to release their products during Q3. Second, due to supply constraints of QFP packaged devices, we are anticipating a delayed shipment of devices from our test and package subcontractor that will negatively impact our Q2 revenue by a few hundred thousand dollars. While we have been assured these devices will be received in time to support our customer’s production schedule, we are forecasting the revenue for Q3. Even with these challenges that are outside of our control, we are forecasting enough growth from EOS S3 and other new products to more than offset the anticipated decline in mature product revenue and deliver revenue growth in Q2. Let’s start now with an update on our embedded FPGA business. During Q4, we completed our test chip tape-out for the GLOBALFOUNDRIES’ 22 nanometer FD-SOI process that is marketed as 22FDX. While delays at GLOBALFOUNDRIES and its packaging partner pushed out the delivery of our qualification devices, they are scheduled to arrive on our dock later this month. Based on this schedule, we anticipate completing our 22FDX qualification this summer. We have ongoing engagements with potential IP customers that include several top-tier semiconductor companies that are targeting 22FDX for new SoC designs that I believe will close later this year. We also have ongoing engagements with top-tier semiconductor companies for new SoC designs targeting our already qualified 40 nanometer processes at GLOBALFOUNDRIES and SMIC that I believe will close during 2018. These SoC designs are moving forward and continue to target the integration of our embedded FPGA IP. In addition to these activities, we are also in the process of porting our eFPGA IP to more advanced fabrication nodes than the 65 nm process we support today at TSMC. In February, we announced the support of our ArcticPro embedded FPGA IP by Aldec, Inc., a world leader in Electronic Design Automation tools. With this, our customers can perform design verification using Aldec's industry-proven Active-HDL FPGA Design and Simulation software and easily migrate designs to and from our Aurora tool suite. The combination of the two tool sets delivers a seamless development environment supporting a simple and complete design flow, from RTL to simulation to bitstream for the embedded FPGA portion of an ASIC or SoC design. In March, we announced joining the RISC-V Foundation. The RISC-V Foundation is a non-profit corporation controlled by its members that directs the future development and drives the adoption of the RISC-V Instruction Set Architecture or ISA. Founded in 2015, the Foundation has more than 100 members representing hardware and software innovators focused on building an open and collaborative community to deliver a free and extensible processor architecture along with its associated ecosystem. This is particularly significant for QuickLogic as there is strong synergy between our embedded FPGA initiative, our membership in the GLOBALFOUNDRIES FDXcelerator Partner Program to facilitate 22FDX SoC designs, and the RISC-V effort. With this, 22FDX customers will be able to seamlessly integrate our embedded FPGA IP and the RISC-V open-source processor technology on the same SoC. Given the increasing interest in our embedded FPGA IP and the impressive traction RISC-V is building with major semiconductor companies, this could prove to be a big deal for QuickLogic. Let’s shift now to our AI initiative, and how it leverages our embedded FPGA IP and our EOS S3 SoC to enable next generation AI in endpoint applications. Together with our ecosystem partners, General Vision, nepes corporation and SensiML, we introduced what we believe is the first comprehensive solution that unleashes the power of next generation AI in endpoint devices. Our solution is trademarked as QuickAI, which includes silicon, software and our new QuickAI development platform. With these resources and tools, OEMs can initiate next-generation AI-enabled endpoint designs today. The benefits of AI are indisputable; virtually every cloud computing company in the world today is developing AI solutions as a high priority. However, the solutions available for cloud applications are too expensive and consume far too much power for endpoint applications. As a result, prior to the introduction of QuickAI, endpoint product designers had to either piece together solutions and build their own development tools, or compromise with a software solution running on a microcontroller or a Digital Signal Processor. QuickAI is a comprehensive solution that enables the immediate development of next generation AI-enabled endpoint devices; a market that ABI Research predicts will ramp very sharply to exceed 270 million devices in 2023. I’ll take a minute now to introduce you to our ecosystem partners, so you can better understand where QuickLogic fits in the value proposition, and why our EOS S3 SoC and embedded FPGA IP are key enabling technologies for next-generation AI in endpoint devices. General Vision is the inventor of NeuroMem, a scalable neural network technology on silicon and an essential enabler for the practical application of artificial vision and artificial intelligence. NeuroMem employs a radically different compute architecture and is vastly more efficient than running AI software on a microcontroller or DSP. For example, a typical DSP for endpoint applications can only handle 32 simultaneous calculations whereas the NeuroMem IC in hand today handles 576 simultaneous calculations. The result is an economical solution that delivers higher performance at significantly lower power consumption. nepes corporation is a leader in advanced semiconductor assembly and packaging technologies. nepes has developed and mass produces the nm500, a NeuroMem-based IC that enables artificial vision and artificial intelligence in endpoint solutions. The nm500, which nepes uses in critical optical inspection applications in its manufacturing processes, is a focal point for the company‘s Future Intelligence business unit. SensiML is a spin out from Intel and a developer of leading-edge software tools that enable the quick and easy generation of application specific pattern recognition code. With this, OEMs can design AI-enabled endpoint solutions that gather data from the wide variety of sensors that are commonly used in IoT applications today. QuickLogic contributes the enabling capability of our embedded FPGA IP and our EOS S3 SoC. With its patented FFE, integrated ARM Cortex M4F microcontroller and embedded FPGA, EOS S3 supports critical pre and post processing capabilities, feature extraction, intelligent power management and in some applications, host processing. In use cases where it’s applicable, the EOS S3’s integrated LPSD enables always-on / always-listening capability to detect voice or in some applications, noise that may warrant further analysis. Let me share a quick example of how this could come together in the real world - In a common feature extraction application like a FIR or FFT filter in an industrial IoT device, our embedded FPGA will consume 80% to 90% less power than a DSP or microcontroller. When this power savings is combined with the similar efficiency improvement that a NeuroMem processor delivers, it presents many new opportunities for designers to employ the benefit of this next generation AI architecture in endpoint designs. With QuickAI software and development tools, designers can turn these opportunities into real products starting now. A point I want to emphasize is that QuickAI is perfectly aligned with our core business model and leverages the value of EOS S3, our embedded FPGA licensing model and most importantly, our patented IP. Due to our high value contribution in next generation AI applications, we believe our gross margin potential for EOS S3 will be comfortably above our historical levels for devices. For more color on QuickAI, our ecosystem partners, our strategy and the markets we are addressing, you can access a recording of last Friday’s Webinar on the Investor Relations page of our website. Let’s shift now to sensor processing in wearable, hearable and IoT applications. In previous conference calls we’ve discussed a wearable design win with a large app company. I’m very proud to announce that Naver Labs selected our EOS S3 for its first consumer product, the AKI smartwatch. AKI was released earlier this week and is being marketed by Korea Telecom now known as KT. With nearly 20 million subscribers, KT is South Korea’s largest wireless carrier. Naver Labs is the highly sophisticated, worldwide product development group that was spun off from Naver. With a market cap approaching $25 billion, Naver is best known for its search engine; cloud computing, AI assistant and its wide variety of apps that are used worldwide. I personally use Naver’s LINE messaging app, which has over 500 million downloads. The focus at Naver Labs is to develop technologies and products that provide what it calls “Ambient Intelligence” and leverage the various apps, resources and technologies developed throughout the Naver organization. The AKI smartwatch demonstrates the benefits of Ambient Intelligence by recognizing a user’s situation, anticipating needs and then providing information and services before they are requested. The AKI smartwatch features an intuitive voice interface that is used to control functions, communicate person to person and to access to Naver’s cloud-based AI resources using the trigger word, “OkiDoki”. Through the use of an integrated Naver app, AKI also supports speech to text and text to speech. AKI also monitors and reports user activity, context and location. AKI augments its integrated GPS with Naver Labs WPS technology to provide precise location even when a user is indoors. With these resources, and its Bluetooth®, Wi-Fi, LTE and WCDMA connectivity, AKI can support any combination of always-on, always-listening, always- connected and always-aware use cases. Since our last conference call, the tier one smartphone OEM that we've discussed in the past has officially locked down its hardware and firmware designs for its wearable that includes our EOS S3. With these important milestones completed, the OEM has initiated its audit of our package and test subcontractor to finalize our device qualification. In parallel with this, the customer is in the process of completing software regression, quality and reliability testing, and is working closely with its third-party app developers. We continue to work very closely with this customer and anticipate receipt of finished test units later this quarter that we will use to expedite the product qualification process. While these activities and accomplished milestones mark clear tangible progress towards the release of this new wearable, due to the fact we do not have a schedule in hand at this time, we are not including any revenue from this design win in our Q2 guidance. The second design opportunity with this customer for a new consumer wearable device is moving forward and we should know if EOS S3 makes the final cut later this quarter. The short story here is if the customer is able to use the new applications processor it is targeting for the design, it will also use our EOS S3 for voice and sensor processing. The important point to note here is our success is aligned with the design approach the customer wants to take. The third design opportunity we have with this customer is for a new consumer hearable device. The customer is currently evaluating the software we delivered last quarter that supports two microphone inputs, beam-forming and advanced noise cancellation. We expect the evaluation will be completed later this quarter, and if our technology is approved, we believe the design will target EOS S3 and move forward rapidly. In our last conference call, I mentioned a design win with a European company that has developed a wearable targeting B2B health and fitness applications. This design uses virtually all of the EOS S3 resources to support host processing, sensor processing and its embedded FPGA as a display driver. In line with the forecast I shared last quarter, we have received an order to ship initial production volume later this quarter. We expect this product will ramp into mass production during the second half of 2018. We have added a second engagement with the European fitness company that I have mentioned in past conference calls. The second engagement will fully leverage the resources of our EOS S3; including its embedded FPGA. We believe that one of the products will move into production late this year and the second one will move into production in mid-2019. I’m very pleased to announce that Murata has selected our EOS S3 for a new voice-enabled Wi-Fi solution that it is demonstrating this week at the IoT/M2M show in Japan. As many of you know, Murata is the worldwide market leader for Wi-Fi modules. In this new solution Murata leverages our EOS S3 SoC to expand its market to include voice-enabled battery powered applications like Smart Speakers and other IoT devices that connect to Wi-Fi networks. In this solution, EOS S3 enables always listening at less than 100uW power consumption, recognizes trigger words and minimizes system power consumption via its intelligent power management. OEMs selecting this Murata solution can differentiate their end product designs further without adding recurring costs by using QuickLogic development tools to leverage EOS S3 resources such as its embedded FPGA and patented FFE. In line with the target we provided in our last conference call, we introduced our new EOS S3LV solution last month. The LV stands for Low Voltage. With this version of the device, designers benefit from a 33% reduction in power consumption, but are limited to a 48 Mhz clock speed. However, when you combine the resources of our patented FFE and embedded FPGA, the total compute power is still more than enough for many applications that benefit from the lowest possible power consumption. We have made very solid progress in the smartphone and tablet markets during the last quarter. We are in the final stages of negotiating an MOU with a significant Japanese smartphone OEM that will cover multiple smartphone designs using EOS S3. This concept smartphone design using our EOS S3 that I mentioned during our February conference call was not completed in time for Mobile World Congress but is currently scheduled for demonstration with the OEM’s lead carrier later this month. Last quarter I mentioned our first EOS S3 design win in a tablet. Our OEM customer for this design is Chinese based Bu Bu Kao Educational Electronics. With 18,000 Kiosks in 600 cities across China and 50 flagship stories in major cities, BBK, which was founded in 1995, is a very well recognized brand in China. The primary applications for EOS S3 in our current design win are to enable voice recognition and provide intelligent power management. With a voice interface, the tablet enables the educational process to start as soon as a child learns to talk. In addition to developing a full curriculum that runs from when a child learns to talk all the way through primary school, the tablet also provides an early introduction to English. In addition to the educational curriculum, BBK has a cooperative agreement with AISpeech that enables users to access its cloud-based AI resources. Given the scope and scale of BBK and the interest in early childhood education in China, I think this tablet has solid volume potential that will begin ramping in Q3. During the last quarter, we have expanded our activity with BBK to include additional engagements. I would now like to turn the call over to Sue for a discussion of the financials. Sue.
Sue Cheung: Thank you, Brian. Good Afternoon and thanks to everyone for joining us today. Please note we are reporting our non-GAAP results. You may refer to the press release we issued today for a detailed reconciliation of our GAAP to non-GAAP results and other financial statements. We have also posted an updated financial table on our IR web page that provides current and historical non-GAAP data. For the first quarter of 2018, total revenue was $2.8 million and within our guidance range. Our new product revenue was $1.3 million, and mature product revenue was $1.5 million. Samsung accounted for 10% of total revenue during the first quarter, consistent with the previous quarter, as we continue to diversify our customer base. Our Q1 2018 gross margin was 51.5%. This was above our forecasted range due to a favorable mix of new product revenue. Operating expenses for Q1 round up to $4.9 million and were within our forecasted range. R&D expenses were $2.5 million and SG&A expenses were $2.3 million. The increase in R&D was driven mostly by the launch of our AI initiative and software tools associated with embedded FPGA. The net total for other income, expense and taxes in Q1 2018 was a $99 thousand charge, which was above our forecast due to foreign tax expenses and currency exchange loss. This resulted in a net loss of approximately $3.5 million, or $0.04 per share, essentially at the midpoint of our forecasted EPS range. We ended the first quarter with approximately $12.6 million in cash. Net cash usage during the first quarter was $4 million and within the forecasted range. Turning to the second quarter 2018 outlook, our revenue guidance for Q2 is approximately $3.1 million, plus or minus 10%. Total revenue is expected to be comprised of approximately $1.7 million of new product revenue and $1.4 million of mature product revenue. The increase in new product revenue is expected to be driven mostly by the growth in sensor processing and continued diversification of our display bridge business. On a non-GAAP basis, we expect our gross margin to be approximately 50% plus or minus 3 percent. We expect our gross margin will continue to benefit from a favorable mix of new product revenue and the ongoing diversification of our customer base and end markets. We are currently forecasting non-GAAP operating expenses at approximately $4.8 million, plus or minus $300 thousand. We expect our non-GAAP R&D expenses to be approximately $2.5 million and non-GAAP SG&A expenses to be approximately $2.3 million. Our R&D expense forecast includes anticipated charges associated with porting our embedded FPGA IP to more advanced fabrication nodes at TSMC. We expect our other income, expense and taxes will be a charge of approximately $60 thousand. At the midpoint of our forecast, our non-GAAP loss is expected to be approximately $3.3 million, or $0.04 per share. As was the case in prior quarters, the main difference between our GAAP to non-GAAP results is our stock-based compensation expense, which we expect to be approximately $480 thousand for the 2nd quarter. In Q2, we expect to use between $3 and $3.5 million in cash. With that, let me now turn the call back over to Brian for his closing remarks.
Brian Faith: I realize today’s call ran longer than usual, but our priority is to provide you with as much transparency as our NDAs will allow and the detail you deserve. It has been a long road; longer than I had imagined. However, we are poised to enter the second half of 2018 with numerous EOS S3 designs waiting only for Amazon’s approval before they move into mass production. The second half will also benefit from the push out of revenue caused by the delay from our test and packaging subcontractor. Much more important than the jumpstart these push-outs will give us for the second half is the fact the designs we’ve been working with large OEMs are beginning to move into production. Small Chinese companies are quick to take risk; they saw the value of EOS S3 and jumped in with both feet. However, large OEMs are very brand-conscience and often measure a dozen times before making a commitment to a new proprietary solution. Naver is well known and highly respected across Asia, and for it to use EOS S3 SoC at the heart of its first consumer product is a very strong validation for QuickLogic. Others, including the BBK design I mentioned earlier, are following close behind. In the world of semiconductor design wins, momentum is very important, and design validation by well-respected OEMs is what drives momentum for new solutions like EOS S3. With world-class embedded FPGA tools available now from EDA industry leaders, Mentor and Aldec, Inc., and the seamless integration of these tools with our Aurora development platform, I believe we are very close to establishing momentum for our ArcticPro embedded FPGA business too. QuickAI adds a very exciting new layer of opportunity for our EOS S3 SoC and our ArcticPro embedded FPGA IP on top of the momentum we are building in our core markets. We believe QuickAI has the potential to substantially expand the applications, use cases and customer base served by QuickLogic and through its leverage of our patented technologies, enable us to build a more diversified and sustainable high margin business. I’m sure you have a lot of questions about the new developments we covered today, so I’ll close now and turn the floor back to the operator.
Operator: Thank you. [Operator Instructions] Our first question comes from Suji Desilva with Roth Capital.
Suji Desilva: Hi Brian. Hi Sue. So a lot to ask about. Let me start maybe with the EOS S3, the constellation of products that are waiting the Amazon close talk. What's the size of that sort of the group of products in terms of the revenue opportunity for you guys when that turns on.
Brian Faith: So the majority of the products that we had in our CES suites are ones that are waiting for this stress specification that you go through the approval process. I would say that individually each of those designs that they are going to be high tens of thousands or up to I would say high hundred of thousand depending on which ODM it is and how they bring that to market. And then for modeling purposes, I think we said publicly use $1.50 to midpoint for EOS S3 and those types of solutions. In certain cases we're more than two. In certain cases, we're under one, but if you use 1.5, you can get a good modeling for that revenue potential.
Suji Desilva: And Brian if I recalled about 10 roughly plus or minus design wins that we're in.
Brian Faith: Yes we had nine at CES. They were here will base and so the majority of those are Amazon based. So our new ones that have come into the funnel since CES, so it actually is a higher number than what we had at CES, but that I would use that as a minimum number to model from.
Suji Desilva: Great. Very helpful color there and on the constraint that has been packaging sub cons, I wasn’t clear which segment that impacts, whether it's new mature products in the magnitude of the impact in the 2Q guidance?
Brian Faith: Yes, so the packaging type is QFP which we have in both mature and new products. It tends to be more of a mature product for us, but in this case there is new product being affected by and I think it's on the order of a few hundred thousand dollars. To be clear by the way, this is not in any way affecting EOS S3 with a display rich products, which do not use QFP packaging. This is the other devices that we have.
Suji Desilva: Got it. Good to know that and then the Tier 1 smartphone opportunity, it feels like it's penalizing the close here. Can you help us size the opportunity and I guess not just as one opportunity, but it sounds like two or three opportunities you might be in as a kind of a platform into this tier 1 smartphone vendor. Any color there be very helpful. Thanks.
Brian Faith: Yes, so all three of them would be in the -- would be over the million unit threshold. I would say probably all three are low single-digit millions of units. I won't say the ASP because you should just use the average that we've been talking about from a modeling point of view, but that's our views. Now a couple of these products are already existing products that there is OEM. So they have sort of an established track record of that. The one that we've been talking about for the longest amount of time this wearable design win that we're wrapping into this next stage of product position with them, that's a new category for this customer. So you have to think about it in those terms, new market for this customer, but it's I think the way they talk about it, it's still going to be in the millions of units range based on how their plan is to take it to market.
Suji Desilva: Okay. And then I had a bunch of question with the AI, but I'll just kind of stick to one for now. Which end markets do you think will be first ones to leverage this AI capability you have, thanks?
Brian Faith: Yes, so let me address that question. Our CTO and SVP of engineering, Tim is in the room, but I think we'll save him for some more technical questions in that area. So for the initial market that we've launched with the ecosystem that we did in our webinar, that is initially going to go out through the IOT broadly that category, more narrowly industrial IOT because that's where a lot of the Intel core was used, that what sensible and have seen some traction and where they work with customers and that's also if you think about what [indiscernible] is talking about using a forward optical pattern of recognition and manufacturing for I think the closest revenue will be where they see opportunity today. That being said, AI is a very broad term and so even today Tim and I were meeting our customer here at QuickLogic. Their CEO came in and he is talking about wearables and hearables in consumer market and what they're trying to do from an AI point of view and you can see that we actually enable some of the core elements of AI with our embedded FPGA and S3 today in a consumer space. So it's actually, it's fairly broad. We can see maybe consumer revenue faster because the markets tend to move faster, but the real target behind that initiative that we put together with those particular ecosystem partners was more IOT and industrial IOT.
Suji Desilva: Okay. Great. Helpful. I will leave it at that. Thank you, guys.
Brian Faith: Thanks Suji.
Sue Cheung: Thank you.
Operator: Thank you. Our next question comes from Richard Shannon with Craig-Hallum.
Richard Shannon: Hi Brian and Sue. Thanks for taking my questions as well. I thought I had a long list of questions prepared before the call and you certainly had a quite a bit to those. So I'll try to restrain myself at least the first time to the queue here. Maybe just a quick housekeeping question for Sue, anyway you can quantify or describe the S3 revenues in the first quarter as well as a display bridge revenues?
Sue Cheung: Okay. So we normally do not break down to that level of detail. So for the first quarter Q1, we'll say, I would say the 100,000 in terms of the EO. Display bridge will be under $1 million.
Richard Shannon: Okay. Well that is helpful. Wanted to ask quickly on the second quarter guidance. You had a lot of moving parts here I think Suji asked some questions kind of break down some of the pieces, wondering maybe Brian if you want to characterize how much lost revenues might be because of the various issues here, the Amazon Alexa delay and the qualification the packaging issue and other things there. Anyway you can quantify how much all that adds up to in any way?
Brian Faith: Let if we look back to the last call that we had and where we thought we would be with Q2 revenue, we were assuming the Amazon spec would be out by then and these customers would actually be taking product from us in Q2. So I think if you add up the net of those two, I would say it's over $500,000 and probably slightly less than $1 million in terms of revenue impact, someone in that range from what we were thinking at the beginning of the year for Q2 yes.
Richard Shannon: Okay. Perfect. That's very helpful. Before we get to AI I just wanted to ask one question, I think you had mentioned that you are, I don’t want to put words in your mouth, so please correct me here, working with TSMC and embedded FPGA, can you talk a little bit about what's going on there? I think you said you're qualified at some older nodes and getting to more leading edge ones. I know that they have at least one older embedded FPGA partners. So maybe you can couch in terms of what they might be bringing you in for relative to what they already have?
Brian Faith: Sure. So to be clear, we stated we're reporting our FPGA into TSMC process. How close we work with TSMC directly, we don’t really discuss and it's probably not be perfect for this call, given we have NDAs with our partners. That being said, we do want to report into TSMC for a more invested note because they are the largest founder in the world in terms of market share and it just makes sense that we would go do that, which just augments our what I feel is a nice offering and foundries where our competitors don’t really exist. You asked the question about where we run at TSMC today. So we actually have devices and architecture that runs with TSMC with our FPGA on 0.35 micron, we have the ability to do 0.25 micron. So this would be an additional note to those that's more recent than those.
Richard Shannon: Okay. Perfect. Let's here maybe one or two questions here on QuickAI. Maybe I'll just ask a very simple high-level question. Especially Brian relative to your commentary about using entry into market here, anyway you can discuss what timeframe you could expect to see revenues emerging here maybe discuss if you have any examples or early test cases of people or partners moving, trying to move through design and production. What could we expect there over the next few to several quarters?
Brian Faith: Yeah it's a good question. So a lot of the knowledge that we have about these markets is coming from our ecosystem partners at this point as we just start to put together the go-to market strategy in detail with them. From what we know, these types of markets can generally do a design in around six months to get the point where you're actually have that data collection stage where you can start collecting data and building the models by which you're going to deploy AI. So I think from a revenue point of view perhaps, you can imagine that you can start to see design wins being announced from us towards the end of the year, if you look at that six month horizon and then it would be a revenue contributor starting from '19 and that's what we're planning on internally.
Richard Shannon: Okay. Do you do you design wins in process right now?
Brian Faith: We don’t have design wins in process, but we do have some early engagements again on behalf of the partners that were already in the space that we are engaging with.
Richard Shannon: Okay. Maybe a last question for me and I'll jump out of line here, as I was doing research related to QuickAI after you announced it last Friday morning I noticed that General Vision has had partnered with to some degree with SG micros, obviously a very large microcontroller company. Looks like they have elected to work with you presumably having a lower power product to work there maybe if you can discuss the partnership and why you’ve restart all these players specifically and maybe why they’ve chosen you as well understanding kind of the fit to each other as well as to the end applications?
Brian Faith: Sure, so first I won't speak directly for General Vision, but I'll just give you a sense of what the ecosystem in general has talked about what we see moving forward and I think I'll answer your question related to ST. So if you go back in time from before Friday, the way people would put together these types of end point applications as they would choose a microcontroller, they choose a software operating system and sensors and then they have to pick how they go to market with AI that could be from hiring data scientists. You can contract business to sense them over these type of people. What we know in the case of the General Vision neurons and in particular the implementation with the Nepes chip is that you need a programmable logic device to connect to Nepes chip into the system with the microcontroller. So that means if you want to deploy neurons, you also need to buy a microcontroller and an FPGA. So the other thing I will say is that and we found this out just by virtue of having these technical press briefings on our launch. One of the guys that we were talking to, said wow, this is amazing. You guys are actually doing this on the same chip because I just got done talking to NXP and their AI strategy is to run software on an MCU. You’ve actually got some hardware blocks that you can optimize for lower power to offload the MCU and accelerate the function and you are dead right. So if you think about now your question, why would somebody use QuickLogic or what value does the ecosystem see with QuickLogic, they can see that if you wanted to deploy hard neurons using that approach, you need FPGA, you need microcontroller. S3 gives you that in the same chip and because it's your lower power and we have hardware accelerators for certain functions like feature extraction or sensor, data acquisitions through our FPJ and through our FFD. So it's a really nice tie into our core value proposition that we can grow from together and the fact we have the M4 MCU, means that if people are used to writing software for general purpose microcontroller via NXP or ST or whoever, imagine some reporting that down into our S3, that's a very straightforward way to do that because it's leveraging all of the developments we've done in S3 with our open platform. So now we're starting to see the fruits of that labor where initially we were designing it for the consumer market. Now we can actually take that into other markets and have other people put their software in the platform as well. Hope that answers your question.
Richard Shannon: That was very helpful. That's enough questions I think, I will jump out of line, but thanks for all the detail. I appreciate Brian and Sue.
Brian Faith: Thanks Richard.
Operator: [Operator Instructions] Our next question comes from Rick Neaton with Rivershore Investment.
Rick Neaton: Hi Brian. Hi Sue. I have one question. For the last two midyear conference calls, you stated confidence that you have a strong second half, what's different about this year? What data point can you again share with us and make your confidence in a strong second half and meeting or exceeding your CAGR goal more probable this year than in the past two, thank you?
Brian Faith: Sure, so let's compare this quarter to a year ago to answer that question. If we look at where we were with mass production shipments of EOS S3, I think today is the first time that I can say that a brand company neighbor the Google and South Korea has actually shipped a product to an end consumer with an EOS S3, not only is that revenue that's validation from a big company, that their product on QuickLogic. And I think that once we gotten out over that threshold that the branding guys taking your product to market, not just a design win but actually shipping in production to the end consumer now we've arrived from EOS E3 point of view and we're building on that momentum and as far the funnel goes, we see our funnel now is way more diverse than it was a year ago. Last year it was very heavily concentrated on this Tier 1 smartphone doing the wearable and the couple of smartphone designs. This year it's very diverse to the extent that I don’t think there is a single opportunity that's close to 10% of that total revenue target. So it's way more diversified than it was in the past. The fact that we actually can talk now smartphone win in revenue with this MOU with this Japanese company, we weren’t talking with you that company last year, where it means we have that company in trying to prove that this actually does what we say it does and now we're there. And then the last thing I'll say is we've probably say about last year being this year of building out the tool and the infrastructure for the embedded FPGA field licensing, this year we have provided that field and we can take that discussion to the next level where they're actually evaluating to make a decision, not waiting for the tool to arrive. And then laying on top of all that, we talked about AI how it's probably going to be a revenue contributor in 2019 that's from a device point of view, but I can guarantee you that we learn more about the FPGA used cases from those systems, we can now take that as messaging back into some of these other companies that we're interested in MPJ and how that enable and bring more value to them. So it's a very fulfilling or virtuous cycle that we're now going through with these engagements and that all of that in total is what gives me this confident in the growth.
Rick Neaton: Okay. Thank you, Brian. I appreciate it.
Brian Faith: Thanks Rick.
Operator: Thank you. Ladies and gentlemen, that concludes the question-and-answer portion of today's call. I would now like to turn the call back over to management for any closing remarks.
Brian Faith: Thank you, operator. We will be participating at the following investor and industry events; the 15th Annual Craig Hallum Institutional Investor Conference in Minneapolis, Minnesota on May 30. Cowen' 46th Annual TMP Conference in New York on May 31. The Roth London Conference on June 20, the Design Automation Conference or DAC in San Francisco on June 24 to 28 and the Sensors Expo Conference in San Jose, June26 to 28. Our next conference call is scheduled for Wednesday, August 08 at 2:30 PM Pacific Time Thank you for your continued support and good bye.
Operator: Ladies and gentlemen, thank you for participating in today’s conference. This does conclude the program. You may all disconnect and have a wonderful day."
-0.0916
